import requests
from bs4 import BeautifulSoup
import pdfkit
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import letter
import os
from langchain_community.document_loaders import TextLoader
from langchain_community.document_loaders import PyPDFLoader

#mostly inneffective dogshit. reportlab is trash compared to pypdf
"""
def text_to_pdf(text_file, pdf_file):
    c = canvas.Canvas(pdf_file, pagesize=letter)
    with open(text_file, 'r') as f:
        text = f.read()
        c.drawString(100, 750, text)
        c.showPage()
        c.save()

# Example usage:

text_file = 'infinite_desktop_text.txt'
pdf_file = 'infinite_desktop.pdf'
text_to_pdf(text_file, pdf_file)
"""
sourceDirectory = "/home/C.O.O.L" 
fileNames = [fileName for fileName in os.listdir(sourceDirectory) if fileName.endswith('.pdf')|fileName.endswith('.cl')] # could add '.pdf'/'.txt' in this case using .cl for code
#hihglight down to this line and click run selection to check if documents are properly retrieved
#then type whos and fileNames in spyder terminal to check your documents loaded correctly


pageList = []

#load PDF files, covnert to text, create list of text contents
for file in fileNames:
    filePath = os.path.join(sourceDirectory,file)
    if file.endswith('.cl') == True:
        loader = TextLoader(file_path = filePath)
    else:
      loader = PyPDFLoader(file_path = filePath)  #alternately use PyPDFLoader/TextLoader
    pages = loader.load()
    pageList.extend(pages)

with open('COOL.txt', 'w') as file:
    for page in pageList:
        file.write(f"{page}\n")

"""
#function to make line by line URL file generated by wget command into a python list
def file_to_list(filename):
    try:
        with open(filename, 'r') as file:
            lines = file.readlines()
            # Remove newline characters
            lines = [line.strip() for line in lines]
            return lines
    except FileNotFoundError:
        print(f"File {filename} not found.")
        return []

# Example usage:
filename = 'GLurl.txt'
URLs = file_to_list(filename)
print(URLs)


text = ""
for URL in URLs: 
    print(URL)
    page = requests.get(URL)
    if(page.ok):
        soup = BeautifulSoup(page.content, "lxml")
        infoDiv = soup.get_text()
        startIndex = infoDiv.find("Name ")
        endIndex = infoDiv.find("Copyright")
        print(f"Usable Chars: {endIndex-startIndex}")
        text = text + infoDiv[startIndex:endIndex]
        print("SUCCESS")
        #function to convert text string to pdf


def text_to_pdf(text, filename):
    options = {
        'page-size': 'A4',
        'margin-top': '0.75in',
        'margin-right': '0.75in',
        'margin-bottom': '0.75in',
        'margin-left': '0.75in',
        'encoding': "UTF-8",
        'no-outline': None
    }
    pdfkit.from_string(text, filename, options=options)

    filename = "infinite_desktop.pdf"
    text_to_pdf(text, filename)
"""


    

 